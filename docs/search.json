[
  {
    "objectID": "workshops/index.html",
    "href": "workshops/index.html",
    "title": "Intro to R: Data Wrangling",
    "section": "",
    "text": "Illustration from Hadley Wickham’s 2019 talk, The Joy of Functional Programming\n\n\n\n\n\n Instructional Documentation\n\n\n Source Code\n\n\n\n\nOverview\nThis workshop was developed for ES40: Critical Thinking and Evidence Based Reasoning at the University of California, Santa Barbara.\n\n\nAbstract\nR is a programming language that enables us to turn data into understanding. In this workshop, we’ll introduce the {dplyr} package of the {tidyverse}, which houses many functions that make data easier to work with, as an introduction to R and its applications for environmental data.\n\n\n{r, echo=FALSE} knitr::include_graphics(\"data_wrangler.png\")\n\nIllustration from Hadley Wickham’s 2019 talk, The Joy of Functional Programming\n\n\n\n\n\n Instructional Documentation\n\n\n Source Code\n\n\n\n\n\nOverview\nThis workshop was developed for ES40: Critical Thinking and Evidence Based Reasoning at the University of California, Santa Barbara.\n\n\nAbstract\nR is a programming language that enables us to turn data into understanding. In this workshop, we’ll introduce the {dplyr} package of the {tidyverse}, which houses many functions that make data easier to work with, as an introduction to R and its applications for environmental data."
  },
  {
    "objectID": "posts/tfp_analysis/index.html",
    "href": "posts/tfp_analysis/index.html",
    "title": "Agriculture Total Factor Productivity Growth in Global Income Classes",
    "section": "",
    "text": "The agricultural sector faces opposing pressures of sustaining a growing population while minimizing its unfavorable outcomes on finite environmental resources1. In an effort to simultaneously move towards these goals, countries around the world have prioritized agricultural productivity. One of the most informative measures of agricultural productivity is total factor productivity (TFP). TFP compares gross outputs of crop, animal and aquaculture products to inputs of land, labor, capital and material resources utilized in farm production2. As gross output increases at a faster rate than total inputs, total factor production improves, which eases tensions on environmental resources and food security, and boosts economic growth3. TFP is expressed generally by the equation: \\[TFP=Y/X\\] where Y represents gross output and X represents total inputs.\nTFP is an important measure for informing policy priorities for agricultural productivity. These policies include investments in research and development, incentivizing economic reforms for farmers, rural education and extension, and improvments in infrastructure4. Understanding the effects of individual inputs on TFP can direct decision making as it relates to resource allocation for these policy investments.\n\n\n\n\n\nThis analysis will regress global TFP indices on inputs of land, labor, capital, and materials to examine the effects of these inputs on gross outputs. This regression can be utilized to maximize TFP growth rates by differentiating efficiency levels of individual inputs as they relate to gross productivity, which can direct resource allocation to technological improvements of inefficient input systems.\nAdditionally, it will examine TFP growth rates for country groupings of income class (defined by the World Bank) by testing for mean differences. It will also forecast TFP growth rates for years 2020-2030 at a global scale and for income classes by employing automated autoregressive moving average (ARIMA) models. Understanding nuances in TFP growth for varying income scales can be useful in further research to refine regressions that direct policy prioritization.\nAll relevant analysis outputs are included in the Analysis section - for detailed code concerning model checking, reference the Model Testing and Supporting Figures section."
  },
  {
    "objectID": "posts/tfp_analysis/index.html#footnotes",
    "href": "posts/tfp_analysis/index.html#footnotes",
    "title": "Agriculture Total Factor Productivity Growth in Global Income Classes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNetwork on Agricultural Total Factor Productivity and the Environment. Oecd.org. Accessed December 4, 2022. https://www.oecd.org/agriculture/topics/network-agricultural-productivity-and-environment/↩︎\nFuglie K, Jelliffe J, Morgan S. Documentation and methods. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/documentation-and-methods/↩︎\nFuglie K, Jelliffe J, Morgan S. Documentation and methods. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/documentation-and-methods/↩︎\nFuglie K, Wang SL. New Evidence Points to Robust But Uneven Productivity Growth in Global Agriculture. Usda.gov. Published September 20, 2012. Accessed December 4, 2022. https://www.ers.usda.gov/amber-waves/2012/september/global-agriculture/↩︎\nFuglie K, Jelliffe J, Morgan S. International agricultural productivity. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/↩︎\nGriffith B. Middle-Income Trap. In: Frontiers in Development Policy. The World Bank; 2011:39-43.↩︎\nFuglie K, Wang SL. New Evidence Points to Robust But Uneven Productivity Growth in Global Agriculture. Usda.gov. Published September 20, 2012. Accessed December 4, 2022. https://www.ers.usda.gov/amber-waves/2012/september/global-agriculture/↩︎\nNetwork on Agricultural Total Factor Productivity and the Environment. Oecd.org. Accessed December 4, 2022. https://www.oecd.org/agriculture/topics/network-agricultural-productivity-and-environment/↩︎\nNetwork on Agricultural Total Factor Productivity and the Environment. Oecd.org. Accessed December 4, 2022. https://www.oecd.org/agriculture/topics/network-agricultural-productivity-and-environment/↩︎\nFuglie K, Jelliffe J, Morgan S. Documentation and methods. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/documentation-and-methods/↩︎\nFuglie K, Jelliffe J, Morgan S. Documentation and methods. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/documentation-and-methods/↩︎\nFuglie K, Wang SL. New Evidence Points to Robust But Uneven Productivity Growth in Global Agriculture. Usda.gov. Published September 20, 2012. Accessed December 4, 2022. https://www.ers.usda.gov/amber-waves/2012/september/global-agriculture/↩︎\nFuglie K, Jelliffe J, Morgan S. International agricultural productivity. Usda.gov. Published October 7, 2022. Accessed December 4, 2022. https://www.ers.usda.gov/data-products/international-agricultural-productivity/↩︎\nGriffith B. Middle-Income Trap. In: Frontiers in Development Policy. The World Bank; 2011:39-43.↩︎\nFuglie K, Wang SL. New Evidence Points to Robust But Uneven Productivity Growth in Global Agriculture. Usda.gov. Published September 20, 2012. Accessed December 4, 2022. https://www.ers.usda.gov/amber-waves/2012/september/global-agriculture/↩︎\nNetwork on Agricultural Total Factor Productivity and the Environment. Oecd.org. Accessed December 4, 2022. https://www.oecd.org/agriculture/topics/network-agricultural-productivity-and-environment/↩︎"
  },
  {
    "objectID": "posts/sobel_ode/index.html",
    "href": "posts/sobel_ode/index.html",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "",
    "text": "In this post, I perform a Sobol sensitivity analysis with an ODE (ordinary differential equation). This analysis is derived from an assignment for EDS230: Modeling Environmental Systems, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nSobol sensitivity analysis is a variance-based approach designed to efficiently sample a parameter space. Sobol quantifies sensitivity by breaking variance outputs into several indices, which are computed using parameter-output variance relationships. These indices include:\n\nFirst Order Sensitivity (Main Effect): variance associated directly with parameter alone\nTotal Effect: variance associated with parameter and interaction with other parameters\nSecond Order Indices: quantification of how parameter pair-wise parameter interactions contribute to output variation\n\nIn this example, we consider the following model of forest growth (where forest size is measures in units of carbon (C)):\ndC/dt = r ⋅ C for forests where C is below a threshold canopy closure\ndC/dt = g ⋅ (1 - C/k) for forests where carbon is at or above the threshold canopy closure and K is a carrying capacity in units of carbon\nThe size of the forest (C), canopy closure threshold and carrying capacity are all in units of carbon. We think of the canopy closure threshold as the size of the forest at which growth rates change from exponential to linear, and we observe r, as early exponential growth rate and g as the linear growth rate once canopy closure is reached."
  },
  {
    "objectID": "posts/sobel_ode/index.html#description",
    "href": "posts/sobel_ode/index.html#description",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "",
    "text": "In this post, I perform a Sobol sensitivity analysis with an ODE (ordinary differential equation). This analysis is derived from an assignment for EDS230: Modeling Environmental Systems, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nSobol sensitivity analysis is a variance-based approach designed to efficiently sample a parameter space. Sobol quantifies sensitivity by breaking variance outputs into several indices, which are computed using parameter-output variance relationships. These indices include:\n\nFirst Order Sensitivity (Main Effect): variance associated directly with parameter alone\nTotal Effect: variance associated with parameter and interaction with other parameters\nSecond Order Indices: quantification of how parameter pair-wise parameter interactions contribute to output variation\n\nIn this example, we consider the following model of forest growth (where forest size is measures in units of carbon (C)):\ndC/dt = r ⋅ C for forests where C is below a threshold canopy closure\ndC/dt = g ⋅ (1 - C/k) for forests where carbon is at or above the threshold canopy closure and K is a carrying capacity in units of carbon\nThe size of the forest (C), canopy closure threshold and carrying capacity are all in units of carbon. We think of the canopy closure threshold as the size of the forest at which growth rates change from exponential to linear, and we observe r, as early exponential growth rate and g as the linear growth rate once canopy closure is reached."
  },
  {
    "objectID": "posts/sobel_ode/index.html#implementing-the-model",
    "href": "posts/sobel_ode/index.html#implementing-the-model",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Implementing the Model",
    "text": "Implementing the Model\nWe begin the sensitivity analysis by implementing the model as a differential equation.\n\n\ncode\n# carbon model\n\n# c = forest size in measured in units of carbon\n# ct = canopy threshold\n# r = exponential growth rate\n# g = linear growth rate at canopy closure\n# k = carrying capacity\n\ncarbon_model &lt;- function(Time, c, params) {\n  \n  ifelse(c &lt; params$ct, \n          delta &lt;- params$r * c,\n          delta &lt;- params$g * (1 - (c/params$k)))\n  \n  return(list(delta))\n}"
  },
  {
    "objectID": "posts/sobel_ode/index.html#running-the-model-with-set-parameters",
    "href": "posts/sobel_ode/index.html#running-the-model-with-set-parameters",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Running the Model with Set Parameters",
    "text": "Running the Model with Set Parameters\nOnce the model is implemented, we run the model for 300 years using given parameters, where there is no uncertainty. We begin with an initial forest size of 10 kg/C and the following parameters:\n\ncanopy closure threshold of 50 kgC\nK = 250 kg C (carrying capacity)\nr = 0.01 (exponential growth rate before canopy closure)\ng = 2 kg/year (linear growth rate after canopy closure)\n\n\n\ncode\n# initial forest size\nc_init &lt;- 10\n\n# assignment of inital perameters\nparam &lt;- list(\n  ct = 50,\n  k = 250,\n  r = 0.01,\n  g = 2\n)\n\n# 300 year simulation time\nsimtimes &lt;- seq(from=1, to=300)\n\n\nWe utilize the ODE solver to run the model for 300 years\n\n\ncode\n# ODE solver implementation\nresult &lt;- ode(times = simtimes, \n              y = c(c = c_init), \n              func = carbon_model, \n              parms = param)\n\n# column renaming\ncolnames(result) &lt;- c(\"time\",\"carbon\")\n\n# store results as a data frame\nresult &lt;-  as.data.frame(result)\n\n\nand then graph the trajectory results.\n\n\ncode\n# graphing results \nggplot(data = result, mapping = aes(x = time, y = carbon)) +\n  geom_point(color = \"darkblue\", size = 3, alpha = 0.6) +\n  labs(title = \"Carbon Levels Over Time\",\n       x = \"Time\",\n       y = \"Carbon\",\n       caption = \"Source: Your data source\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\n        axis.title = element_text(face = \"bold\"),\n        plot.caption = element_text(hjust = 1))"
  },
  {
    "objectID": "posts/sobel_ode/index.html#running-a-sobol-global",
    "href": "posts/sobel_ode/index.html#running-a-sobol-global",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Running a Sobol Global",
    "text": "Running a Sobol Global\nAfter we have run the model with given parameters, we run a sobol global sensitivity analysis, varying all parameters at the same time. This will help us to explore how the estimated maximum forest size varies within the parameters:\n\npre-canopy closure growth rate (r)\npost-canopy closure growth rate (g)\ncanopy closure threshold and carrying capacity (K)\n\nFor this exercise, we assume that parameters are all normally distributed with means as given in initial parameters and standard deviation of 10% of the mean value.\n\n\ncode\n#set base params\nct_base = 50\nk_base = 250\nr_base = 0.01\ng_base = 2\n\n#set sd multiplier\nsd = 0.1\n\n#first set of parameter samples\nct &lt;- rnorm(mean=ct_base, sd=ct_base*sd, n=300)\nk &lt;- rnorm(mean=k_base, sd=k_base*sd, n=300)\nr &lt;- rnorm(mean=r_base, sd=r_base*sd, n=300)\ng &lt;- rnorm(mean=g_base, sd=g_base*sd, n=300)\nX1 = cbind.data.frame(ct=ct, k=k, r=r, g=g)\n\n#repeat the process\nct &lt;- rnorm(mean=ct_base, sd=ct_base*sd, n=300)\nk &lt;- rnorm(mean=k_base, sd=k_base*sd, n=300)\nr &lt;- rnorm(mean=r_base, sd=r_base*sd, n=300)\ng &lt;- rnorm(mean=g_base, sd=g_base*sd, n=300)\nX2 = cbind.data.frame(ct=ct, k=k, r=r, g=g)\n\n#mapping to account for negative values\nX1 = X1 %&gt;% map_df(pmax, 0.0)\nX2 = X2 %&gt;% map_df(pmax, 0.0)\n\n#sobol parameters\nsens_carbon &lt;- sobolSalt(model = NULL, X1, X2, nboot = 300)\n\n# naming output columns \ncolnames(sens_carbon$X) &lt;- c(\"ct\",\"k\", \"r\", \"g\")\n\n\n\n\ncode\n# function to return max carbon  \ncompute_max = function(results) {\n  \n  max_carbon = results$carbon[300]\n  \n  return(list(max_carbon = max_carbon))\n}\n\n# function for ODEsolve\ncarbon_wrapper &lt;- function(c_initial, ct, k, r, g, simtimes, func) {\n  parms = list(ct=ct, k=k, r=r, g=g)\n  results = ode(y= c_initial, times= simtimes, func= func, parms= parms)\n  colnames(results) = c(\"time\",\"carbon\")\n  metrics = compute_max(as.data.frame(results))\n  return(metrics)\n}\n\n\n\n\ncode\nallresults = as.data.frame(sens_carbon$X) %&gt;% \n  pmap(carbon_wrapper, \n       c_initial=c_init, \n       simtimes=simtimes, \n       func=carbon_model)\n\n#take the results out of the list \nallres = allresults %&gt;% map_dfr(`[`,c(\"max_carbon\"))\n\n\nWe graph the results of the sensitivity analysis as a boxplot of maximum forest size and record sobol indices S and T.\n\n\ncode\n# box plot of max carbon\nggplot(data = allres, aes(x = \"Maximum Forest Size\", y = max_carbon)) +\n  geom_boxplot(fill = \"darkblue\", outlier.shape = NA) +\n  labs(title = \"Boxplot of Maximum Carbon Value\",\n       y = \"Max Carbon\",\n       x = \"\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\n        axis.title.y = element_text(face = \"bold\"),\n        plot.caption = element_text(hjust = 1)) +\n  coord_flip()\n\n\n\n\n\n\n\ncode\n# record the indices\nsens_carbon_maxcarbon = sensitivity::tell(sens_carbon,allres$max_carbon)\n\n# First-order indices table\nfirst_order_indices &lt;- sens_carbon_maxcarbon$S\nrownames(first_order_indices) &lt;- c(\"ct\", \"k\", \"r\", \"g\")  # Rename rows with variable names\nkable_first_order &lt;- kable(first_order_indices, caption = \"First-Order Indices\") %&gt;%\n  kable_styling(\"striped\", full_width = FALSE) \n\n# Total sensitivity index table\ntotal_sensitivity_index &lt;- sens_carbon_maxcarbon$T\nrownames(total_sensitivity_index) &lt;- c(\"ct\", \"k\", \"r\", \"g\")  # Rename rows with variable names\nkable_total_sensitivity &lt;- kable(total_sensitivity_index, caption = \"Total Sensitivity Index\") %&gt;%\n  kable_styling(\"striped\", full_width = FALSE)\n\n# Print the tables\nkable_first_order\n\n\n\nFirst-Order Indices\n\n\n\noriginal\nbias\nstd. error\nmin. c.i.\nmax. c.i.\n\n\n\n\nct\n0.0289291\n0.0030741\n0.0579539\n-0.0883667\n0.1443944\n\n\nk\n0.3119509\n0.0017883\n0.0592179\n0.1853595\n0.4378133\n\n\nr\n0.3574912\n-0.0021605\n0.0568834\n0.2467880\n0.4698169\n\n\ng\n0.1462864\n0.0041816\n0.0629863\n0.0177222\n0.2618441\n\n\n\n\n\n\n\ncode\nkable_total_sensitivity\n\n\n\nTotal Sensitivity Index\n\n\n\noriginal\nbias\nstd. error\nmin. c.i.\nmax. c.i.\n\n\n\n\nct\n0.0735177\n0.0003958\n0.0073669\n0.0581179\n0.0858989\n\n\nk\n0.3454228\n-0.0000529\n0.0395123\n0.2640661\n0.4232375\n\n\nr\n0.4382633\n0.0004716\n0.0527044\n0.3202956\n0.5390899\n\n\ng\n0.1810172\n0.0012797\n0.0220721\n0.1332663\n0.2220225\n\n\n\n\n\n\n\nConsidering the range of parameter variations, a shift exceeding 50% in the maximum carbon levels within the forest becomes apparent. Notably, both the first-order and total sensitivity analyses underscore the significance of the carrying capacity (k) and exponential growth rate (r) as pivotal factors in influencing the extent of variability in maximum carbon levels. Foreseeing the potential impact of climate change on forest dynamics, it is plausible to anticipate alterations in the carrying capacity. For instance, factors such as soil nutrient depletion could curtail the forest’s capacity to support tree growth. In light of this scenario, a corresponding decline in the overall carbon content within forests could be anticipated."
  },
  {
    "objectID": "posts/sobel_ode/index.html#description-1",
    "href": "posts/sobel_ode/index.html#description-1",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Description",
    "text": "Description\nIn this post, I perform a Sobol sensitivity analysis with an ODE (ordinary differential equation). This analysis is derived from an assignment for EDS230: Modeling Environmental Systems, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nSobol sensitivity analysis is a variance-based approach designed to efficiently sample a parameter space. Sobol quantifies sensitivity by breaking variance outputs into several indices, which are computed using parameter-output variance relationships. These indices include:\n\nFirst Order Sensitivity (Main Effect): variance associated directly with parameter alone\nTotal Effect: variance associated with parameter and interaction with other parameters\nSecond Order Indices: quantification of how parameter pair-wise parameter interactions contribute to output variation\n\nIn this example, we consider the following model of forest growth (where forest size is measures in units of carbon (C)):\ndC/dt = r ⋅ C for forests where C is below a threshold canopy closure\ndC/dt = g ⋅ (1 - C/k) for forests where carbon is at or above the threshold canopy closure and K is a carrying capacity in units of carbon\nThe size of the forest (C), canopy closure threshold and carrying capacity are all in units of carbon. We think of the canopy closure threshold as the size of the forest at which growth rates change from exponential to linear, and we observe r, as early exponential growth rate and g as the linear growth rate once canopy closure is reached."
  },
  {
    "objectID": "posts/sobel_ode/index.html#implementing-the-model-1",
    "href": "posts/sobel_ode/index.html#implementing-the-model-1",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Implementing the Model",
    "text": "Implementing the Model\nWe begin the sensitivity analysis by implementing the model as a differential equation.\n{r include=FALSE} # packages rm(list = ls()) if (\"package:kableExtra\" %in% search()) {   detach(\"package:kableExtra\", unload=TRUE) } library(tidyverse) library(deSolve) library(sensitivity) library(knitr) library(kableExtra) library(sjPlot)\n# carbon model\n\n# c = forest size in measured in units of carbon\n# ct = canopy threshold\n# r = exponential growth rate\n# g = linear growth rate at canopy closure\n# k = carrying capacity\n\ncarbon_model &lt;- function(Time, c, params) {\n  \n  ifelse(c &lt; params$ct, \n          delta &lt;- params$r * c,\n          delta &lt;- params$g * (1 - (c/params$k)))\n  \n  return(list(delta))\n}"
  },
  {
    "objectID": "posts/sobel_ode/index.html#running-the-model-with-set-parameters-1",
    "href": "posts/sobel_ode/index.html#running-the-model-with-set-parameters-1",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Running the Model with Set Parameters",
    "text": "Running the Model with Set Parameters\nOnce the model is implemented, we run the model for 300 years using given parameters, where there is no uncertainty. We begin with an initial forest size of 10 kg/C and the following parameters:\n\ncanopy closure threshold of 50 kgC\nK = 250 kg C (carrying capacity)\nr = 0.01 (exponential growth rate before canopy closure)\ng = 2 kg/year (linear growth rate after canopy closure)\n\n# initial forest size\nc_init &lt;- 10\n\n# assignment of inital perameters\nparam &lt;- list(\n  ct = 50,\n  k = 250,\n  r = 0.01,\n  g = 2\n)\n\n# 300 year simulation time\nsimtimes &lt;- seq(from=1, to=300)\nWe utilize the ODE solver to run the model for 300 years\n# ODE solver implementation\nresult &lt;- ode(times = simtimes, \n              y = c(c = c_init), \n              func = carbon_model, \n              parms = param)\n\n# column renaming\ncolnames(result) &lt;- c(\"time\",\"carbon\")\n\n# store results as a data frame\nresult &lt;-  as.data.frame(result)\nand then graph the trajectory results.\n# graphing results \nggplot(data = result, mapping = aes(x = time, y = carbon)) +\n  geom_point(color = \"darkblue\", size = 3, alpha = 0.6) +\n  labs(title = \"Carbon Levels Over Time\",\n       x = \"Time\",\n       y = \"Carbon\",\n       caption = \"Source: Your data source\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\n        axis.title = element_text(face = \"bold\"),\n        plot.caption = element_text(hjust = 1))"
  },
  {
    "objectID": "posts/sobel_ode/index.html#running-a-sobol-global-1",
    "href": "posts/sobel_ode/index.html#running-a-sobol-global-1",
    "title": "Using Sobol Sensitivity Analysis with an ODE",
    "section": "Running a Sobol Global",
    "text": "Running a Sobol Global\nAfter we have run the model with given parameters, we run a sobol global sensitivity analysis, varying all parameters at the same time. This will help us to explore how the estimated maximum forest size varies within the parameters:\n\npre-canopy closure growth rate (r)\npost-canopy closure growth rate (g)\ncanopy closure threshold and carrying capacity (K)\n\nFor this exercise, we assume that parameters are all normally distributed with means as given in initial parameters and standard deviation of 10% of the mean value.\n#set base params\nct_base = 50\nk_base = 250\nr_base = 0.01\ng_base = 2\n\n#set sd multiplier\nsd = 0.1\n\n#first set of parameter samples\nct &lt;- rnorm(mean=ct_base, sd=ct_base*sd, n=300)\nk &lt;- rnorm(mean=k_base, sd=k_base*sd, n=300)\nr &lt;- rnorm(mean=r_base, sd=r_base*sd, n=300)\ng &lt;- rnorm(mean=g_base, sd=g_base*sd, n=300)\nX1 = cbind.data.frame(ct=ct, k=k, r=r, g=g)\n\n#repeat the process\nct &lt;- rnorm(mean=ct_base, sd=ct_base*sd, n=300)\nk &lt;- rnorm(mean=k_base, sd=k_base*sd, n=300)\nr &lt;- rnorm(mean=r_base, sd=r_base*sd, n=300)\ng &lt;- rnorm(mean=g_base, sd=g_base*sd, n=300)\nX2 = cbind.data.frame(ct=ct, k=k, r=r, g=g)\n\n#mapping to account for negative values\nX1 = X1 %&gt;% map_df(pmax, 0.0)\nX2 = X2 %&gt;% map_df(pmax, 0.0)\n\n#sobol parameters\nsens_carbon &lt;- sobolSalt(model = NULL, X1, X2, nboot = 300)\n\n# naming output columns \ncolnames(sens_carbon$X) &lt;- c(\"ct\",\"k\", \"r\", \"g\")\n# function to return max carbon  \ncompute_max = function(results) {\n  \n  max_carbon = results$carbon[300]\n  \n  return(list(max_carbon = max_carbon))\n}\n\n# function for ODEsolve\ncarbon_wrapper &lt;- function(c_initial, ct, k, r, g, simtimes, func) {\n  parms = list(ct=ct, k=k, r=r, g=g)\n  results = ode(y= c_initial, times= simtimes, func= func, parms= parms)\n  colnames(results) = c(\"time\",\"carbon\")\n  metrics = compute_max(as.data.frame(results))\n  return(metrics)\n}\nallresults = as.data.frame(sens_carbon$X) %&gt;% \n  pmap(carbon_wrapper, \n       c_initial=c_init, \n       simtimes=simtimes, \n       func=carbon_model)\n\n#take the results out of the list \nallres = allresults %&gt;% map_dfr(`[`,c(\"max_carbon\"))\nWe graph the results of the sensitivity analysis as a boxplot of maximum forest size and record sobol indices S and T.\n# box plot of max carbon\nggplot(data = allres, aes(x = \"Maximum Forest Size\", y = max_carbon)) +\n  geom_boxplot(fill = \"darkblue\", outlier.shape = NA) +\n  labs(title = \"Boxplot of Maximum Carbon Value\",\n       y = \"Max Carbon\",\n       x = \"\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\n        axis.title.y = element_text(face = \"bold\"),\n        plot.caption = element_text(hjust = 1)) +\n  coord_flip()\n# record the indices\nsens_carbon_maxcarbon = sensitivity::tell(sens_carbon,allres$max_carbon)\n\n# First-order indices table\nfirst_order_indices &lt;- sens_carbon_maxcarbon$S\nrownames(first_order_indices) &lt;- c(\"ct\", \"k\", \"r\", \"g\")  # Rename rows with variable names\nkable_first_order &lt;- kable(first_order_indices, caption = \"First-Order Indices\") %&gt;%\n  kable_styling(\"striped\", full_width = FALSE) \n\n# Total sensitivity index table\ntotal_sensitivity_index &lt;- sens_carbon_maxcarbon$T\nrownames(total_sensitivity_index) &lt;- c(\"ct\", \"k\", \"r\", \"g\")  # Rename rows with variable names\nkable_total_sensitivity &lt;- kable(total_sensitivity_index, caption = \"Total Sensitivity Index\") %&gt;%\n  kable_styling(\"striped\", full_width = FALSE)\n\n# Print the tables\nkable_first_order\nkable_total_sensitivity\nConsidering the range of parameter variations, a shift exceeding 50% in the maximum carbon levels within the forest becomes apparent. Notably, both the first-order and total sensitivity analyses underscore the significance of the carrying capacity (k) and exponential growth rate (r) as pivotal factors in influencing the extent of variability in maximum carbon levels. Foreseeing the potential impact of climate change on forest dynamics, it is plausible to anticipate alterations in the carrying capacity. For instance, factors such as soil nutrient depletion could curtail the forest’s capacity to support tree growth. In light of this scenario, a corresponding decline in the overall carbon content within forests could be anticipated."
  },
  {
    "objectID": "posts/boosted_eels/index.html",
    "href": "posts/boosted_eels/index.html",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "",
    "text": "In this post, I perform a case study example of species distribution modeling in a reproduction of the work done by Edith et al. 2008 [1]. For this case study, we model the short-finned eel (Anguilla australis) species using Boosted Regression Trees. This analysis is derived from an assignment for EDS232: Machine Learning in Environmental Science, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nBoosted regression trees, also known as gradient boosting machines, are machine learning techniques that combine concepts of regression trees (relating responses to predictors using recursive binary splits) and iterative boosting (an adaptive method for combining simple models to improve predictive performance). In this case study, decision trees are built sequentially using extreme gradient boosting to classify the presence or absence of short-finned eel in a given location with covariates including temperature, slope, rainy days, etc. The work provided by Edith et al. utilizes the {gbm} package in R, while this analysis follows a {tidymodels} approach in R."
  },
  {
    "objectID": "posts/boosted_eels/index.html#description",
    "href": "posts/boosted_eels/index.html#description",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "",
    "text": "In this post, I perform a case study example of species distribution modeling in a reproduction of the work done by Edith et al. 2008 [1]. For this case study, we model the short-finned eel (Anguilla australis) species using Boosted Regression Trees. This analysis is derived from an assignment for EDS232: Machine Learning in Environmental Science, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nBoosted regression trees, also known as gradient boosting machines, are machine learning techniques that combine concepts of regression trees (relating responses to predictors using recursive binary splits) and iterative boosting (an adaptive method for combining simple models to improve predictive performance). In this case study, decision trees are built sequentially using extreme gradient boosting to classify the presence or absence of short-finned eel in a given location with covariates including temperature, slope, rainy days, etc. The work provided by Edith et al. utilizes the {gbm} package in R, while this analysis follows a {tidymodels} approach in R."
  },
  {
    "objectID": "posts/boosted_eels/index.html#data",
    "href": "posts/boosted_eels/index.html#data",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Data",
    "text": "Data\nOur data for this analysis, “eel.model.data.csv” were retrived from the supplemental information of Edith et al. 2008. These data include the following variables:\n\n\n\nFigure 1: Table 1. from Elith et al. 2008 displaying the variables included in the analysis.\n\n\n\n\ncode\n# load required libraries\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(glmnet)\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(sjPlot)\nlibrary(pROC)\nlibrary(RColorBrewer)\n\n\neel_data &lt;- eel_data_raw |&gt; \n  janitor::clean_names() \n\n# remove site number from modeling data\neel_model &lt;- eel_data[,-1]\n\n# convert presence of angaus, downstream obstructions, and fishing methods to factors\neel_model$angaus &lt;- as.factor(eel_model$angaus)\neel_model$ds_dam &lt;- as.factor(eel_model$ds_dam)\neel_model$method &lt;- as.factor(eel_model$method)\n\ntab_df(eel_data[1:5,],\n       title = \"Table. 1\")\n\n\n\nTable. 1\n\n\nsite\nangaus\nseg_sum_t\nseg_t_seas\nseg_low_flow\nds_dist\nds_max_slope\nus_avg_t\nus_rain_days\nus_slope\nus_native\nds_dam\nmethod\nloc_sed\n\n\n1\n0\n16.00\n-0.10\n1.04\n50.20\n0.57\n0.09\n2.47\n9.80\n0.81\n0\nelectric\n4.80\n\n\n2\n1\n18.70\n1.51\n1.00\n132.53\n1.15\n0.20\n1.15\n8.30\n0.34\n0\nelectric\n2.00\n\n\n3\n0\n18.30\n0.37\n1.00\n107.44\n0.57\n0.49\n0.85\n0.40\n0.00\n0\nspo\n1.00\n\n\n4\n0\n16.70\n-3.80\n1.00\n166.82\n1.72\n0.90\n0.21\n0.40\n0.22\n1\nelectric\n4.00\n\n\n5\n1\n17.20\n0.33\n1.00\n3.95\n1.15\n-1.20\n1.98\n21.90\n0.96\n0\nelectric\n4.70"
  },
  {
    "objectID": "posts/boosted_eels/index.html#split-and-resample",
    "href": "posts/boosted_eels/index.html#split-and-resample",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Split and Resample",
    "text": "Split and Resample\nWe split the above data into a training and test set, stratifying by the outcome score (angaus) to maintain class balance, improve generalization, and ensure the reliability of evaluation in modeling performances. We then use a 10-fold cross validation to resample the training set, also stratified by outcome score.\n\n\ncode\n# set a seed for reproducibility\nset.seed(123)\n\n#stratified sampling with the {rsample} package\neel_split &lt;- initial_split(data = eel_model, prop = 0.7, strata = angaus)\n\neel_train &lt;- training(eel_split)\neel_test &lt;- testing(eel_split)\n\n# 10-fold cross validation, stratified by our outcome variable, angaus \ncv_folds &lt;- eel_train |&gt; \n  vfold_cv(v=10, strata = angaus)"
  },
  {
    "objectID": "posts/boosted_eels/index.html#preprocess",
    "href": "posts/boosted_eels/index.html#preprocess",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Preprocess",
    "text": "Preprocess\nNext, we create a recipe to prepape the data for the XGBoost model. For this analysis, we are interested in predicting the binary outcome variable angaus, which indicates presence or absence of the eel species Anguilla australis.\n\n\ncode\n# create a recipe \nboost_rec &lt;- recipe(angaus ~., data = eel_train) |&gt; \n  step_normalize(all_numeric()) |&gt; \n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |&gt; \n  prep()\n\n# bake to check recipe\nbaked_train &lt;- bake(boost_rec, eel_train) \nbaked_test &lt;- bake(boost_rec, eel_test)"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tuning-xgboost",
    "href": "posts/boosted_eels/index.html#tuning-xgboost",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tuning XGBoost",
    "text": "Tuning XGBoost\n\nTune Learning Rate\nTo begin, we perform tuning on just the learn_rate parameter.\nWe create a model specification using {xbgoost} for the estimation, specifying only the learn_rate parameter for tuning.\n\n\ncode\n#create a model for specification\nlearn_spec &lt;- boost_tree(learn_rate = tune()) |&gt; \n  set_engine('xgboost') |&gt; \n  set_mode('classification') \n\n\nNext, we build a grid to tune our model by using a range of learning rate parameter values.\n\n\ncode\n#set a grid to tune hyperparameter values\nlearn_grid &lt;- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))\n\n\nThen, we define a new workflow and tune the model using the learning rate grid.\n\n\ncode\n#define a new workflow \nlearn_wf &lt;- workflow() |&gt; \n  add_model(learn_spec) |&gt; \n  add_recipe(boost_rec)\n\ndoParallel::registerDoParallel()\nset.seed(123)\n\n#tune the model\nlearn_tune &lt;- learn_wf |&gt; \n  tune_grid(cv_folds, grid=learn_grid) \n\n#show the performance of the best models \nshow_best(learn_tune, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 2',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various learning rate parameter values.',\n         show.footnote=TRUE)\n\n\n\nTable 2\n\n\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n0.2690\nroc_auc\nbinary\n0.8524\n10\n0.0143\nPreprocessor1_Model27\n\n\n\n0.1862\nroc_auc\nbinary\n0.8451\n10\n0.0086\nPreprocessor1_Model19\n\n\n\n0.2586\nroc_auc\nbinary\n0.8444\n10\n0.0120\nPreprocessor1_Model26\n\n\n\n0.2380\nroc_auc\nbinary\n0.8442\n10\n0.0128\nPreprocessor1_Model24\n\n\n\n0.1759\nroc_auc\nbinary\n0.8434\n10\n0.0129\nPreprocessor1_Model18\n\n\n\nTop performing models and their associated estimates for various learning rate parameter values.\n\n\n\n\n\n\n\ncode\n#save the best model parameters to be used in future tuning\nbest_learnrate &lt;- as.numeric(show_best(learn_tune, metric = 'roc_auc')[1,1])"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tune-tree-parameters",
    "href": "posts/boosted_eels/index.html#tune-tree-parameters",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tune Tree Parameters",
    "text": "Tune Tree Parameters\nFollowing the tuning of the learning rate parameter, we create a new specification with a set optimized learning rate from our previous optimization. Now, we shift our focus on tuning the tree parameters.\n\n\ncode\n#create a new specificatin with set learning rate \ntree_spec &lt;- boost_tree(learn_rate = best_learnrate,\n                         min_n = tune(),\n                         tree_depth = tune(),\n                         loss_reduction = tune(),\n                         trees = 3000) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost')\n\n\nAgain, we create a tuning grid, this time utilizing grid_max_entropy() to get a representative sampling of the parameter space.\n\n\ncode\n#specify parameters for the tuning grid \ntree_params &lt;- dials::parameters(min_n(),\n                           tree_depth(),\n                           loss_reduction())\n\n#set the tuning grid \ntree_grid &lt;- grid_max_entropy(tree_params, size = 20)\n\n#define a new workflow \ntree_wf &lt;- workflow() |&gt; \n  add_model(tree_spec) |&gt; \n  add_recipe(boost_rec)\n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n#tune the model\ntree_tuned &lt;- tree_wf |&gt; \n  tune_grid(cv_folds, grid = tree_grid)\n\n#show the performance of the best models \nshow_best(tree_tuned, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 3',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various tree parameter values.',\n         show.footnote = TRUE)\n\n\n\nTable 3\n\n\nmin_n\ntree_depth\nloss_reduction\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n3\n4\n0.0010\nroc_auc\nbinary\n0.8572\n10\n0.0154\nPreprocessor1_Model12\n\n\n\n6\n11\n0.0000\nroc_auc\nbinary\n0.8544\n10\n0.0150\nPreprocessor1_Model10\n\n\n\n4\n2\n0.0000\nroc_auc\nbinary\n0.8528\n10\n0.0143\nPreprocessor1_Model14\n\n\n\n7\n9\n4.9468\nroc_auc\nbinary\n0.8492\n10\n0.0130\nPreprocessor1_Model04\n\n\n\n4\n15\n0.0000\nroc_auc\nbinary\n0.8472\n10\n0.0141\nPreprocessor1_Model11\n\n\n\nTop performing models and their associated estimates for various tree parameter values.\n\n\n\n\n\n\n\ncode\n#save the best model parameters to be used for future tuning\nbest_minn &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,1])\n\nbest_treedepth &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,2])\n\nbest_lossreduction &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,3])"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tune-stochastic-parameters",
    "href": "posts/boosted_eels/index.html#tune-stochastic-parameters",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tune Stochastic Parameters",
    "text": "Tune Stochastic Parameters\nWe create one final specification, setting the learn rate and tree parameters to their optimal values defined in previous tuning iterations. Our final tuning is of the stochastic parameters.\n\n\ncode\n#create a new specificatin with set learning rate and tree parameters\nstoch_tune &lt;- boost_tree(learn_rate = best_learnrate,\n                         min_n = best_minn,\n                         tree_depth = best_treedepth,\n                         loss_reduction = best_lossreduction,\n                         trees = 3000,\n                         mtry = tune(), \n                         sample_size = tune()) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost')\n\n\nWe set up a tuning grid, again utilizing grid_max_entropy().\n\n\ncode\n#set parameters for the tuning grid \nstoch_params &lt;- parameters(finalize(mtry(), eel_train),\n                          sample_size = sample_prop())\n\n#set the tuning grid \nstoch_grid &lt;- grid_max_entropy(stoch_params, size = 20)\n\n#define a new workflow \nstoch_wf &lt;- workflow() |&gt; \n  add_model(stoch_tune) |&gt; \n  add_recipe(boost_rec) \n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n#tune the model \nstoch_tuned &lt;- stoch_wf |&gt; \n  tune_grid(cv_folds, grid = stoch_grid)\n\n#show the performance of the best models \nshow_best(stoch_tuned, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 4',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various stochiastic parameter values.',\n         show.footnote = TRUE)\n\n\n\nTable 4\n\n\nmtry\nsample_size\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n3\n0.9907\nroc_auc\nbinary\n0.8618\n10\n0.0136\nPreprocessor1_Model04\n\n\n\n8\n0.9930\nroc_auc\nbinary\n0.8586\n10\n0.0129\nPreprocessor1_Model19\n\n\n\n8\n0.7407\nroc_auc\nbinary\n0.8574\n10\n0.0151\nPreprocessor1_Model18\n\n\n\n2\n0.8529\nroc_auc\nbinary\n0.8559\n10\n0.0128\nPreprocessor1_Model10\n\n\n\n10\n0.8646\nroc_auc\nbinary\n0.8545\n10\n0.0137\nPreprocessor1_Model06\n\n\n\nTop performing models and their associated estimates for various stochiastic parameter values.\n\n\n\n\n\n\n\ncode\n#save the best model parameters to be used for model finalization\nbest_mtry &lt;- as.numeric(show_best(stoch_tuned, metric = 'roc_auc')[1,1])\nbest_samplesize &lt;- as.numeric(show_best(stoch_tuned, metric = 'roc_auc')[1,2])\n\n\nNow that we have tuned all of our relevant hyperparameters, we assemble a final workflow and do a final fit.\n\n\ncode\n#create a final specification with all set optimized parameters \nfinal_model &lt;-  boost_tree(learn_rate = best_learnrate,\n                         min_n = best_minn,\n                         tree_depth = best_treedepth,\n                         loss_reduction = best_lossreduction,\n                         trees = 3000,\n                         mtry = best_mtry, \n                         sample_size = best_samplesize) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost') \n\n#define a final workflow \nfinal_wf &lt;- workflow() |&gt; \n  add_model(final_model) |&gt; \n  add_recipe(boost_rec) \n\n#fit training data on final wf\nfinal_fit &lt;- final_wf |&gt; \n  fit(eel_train)\n\nfinal_eel_fit &lt;- last_fit(final_model, angaus~., eel_split)\n\nfinal_pred &lt;- as.data.frame(final_eel_fit$.predictions)\n\ntab_df(head(final_pred),\n       title = 'Table 5',\n       digits = 4,\n       footnote = 'Predictions of Angaus presence on test data.',\n       show.footnote = TRUE)\n\n\n\nTable 5\n\n\n.pred_0\n.pred_1\n.row\n.pred_class\nangaus\n.config\n\n\n\n0.9999\n0.0001\n1\n0\n0\nPreprocessor1_Model1\n\n\n\n0.0085\n0.9915\n2\n1\n1\nPreprocessor1_Model1\n\n\n\n0.9810\n0.0190\n3\n0\n0\nPreprocessor1_Model1\n\n\n\n0.9468\n0.0532\n4\n0\n0\nPreprocessor1_Model1\n\n\n\n0.9995\n0.0005\n9\n0\n0\nPreprocessor1_Model1\n\n\n\n0.2945\n0.7055\n10\n1\n1\nPreprocessor1_Model1\n\n\n\nPredictions of Angaus presence on test data.\n\n\n\n\n\n\n\n\n\ncode\n#bind predictions and original data \neel_test_bind &lt;- cbind(eel_test, final_eel_fit$.predictions)\n\n#remove duplicate column\neel_test_bind &lt;- eel_test_bind[,-1]\n\n#compute a confusion matrix\nconfusion_matrix &lt;- eel_test_bind |&gt; \n  yardstick::conf_mat(truth = angaus, estimate = .pred_class)\n\nautoplot(confusion_matrix, type = \"heatmap\") +\n  scale_fill_gradient(low = \"#C7E9FB\", high = \"#084594\") +\n  theme(axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\")) +\n  labs(title = \"Figure 2: Confusion matrix of predictions on test data.\")\n\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\ncode\n# store accuracy metrics \nfinal_metrics &lt;- final_eel_fit$.metrics\n\ntab_df(final_metrics,\n       title = 'Table 6',\n       digits = 4,\n       footnote = 'Accuracy and Area Under the Receiver Operator Curve (ROC) of the final fit.',\n       show.footnote = TRUE)\n\n\n\nTable 6\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.81063122923588\nPreprocessor1_Model1\n\n\n\nroc_auc\nbinary\n0.819193989071038\nPreprocessor1_Model1\n\n\n\nAccuracy and Area Under the Receiver Operator Curve (ROC) of the final fit.\n\n\n\n\n\n\n\nThe final model has an accuracy of 0.80. The ROC area under the curve is 0.82."
  },
  {
    "objectID": "posts/boosted_eels/index.html#fit-model-evaluation-data-and-compare-performance",
    "href": "posts/boosted_eels/index.html#fit-model-evaluation-data-and-compare-performance",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Fit model evaluation data and compare performance",
    "text": "Fit model evaluation data and compare performance\n\n\ncode\n#read in evaluation data \neval_data &lt;- read_csv('eel.eval.data.csv', show_col_types = FALSE) |&gt; \n  janitor::clean_names() \n\n# convert presence of angaus, downstream obstructions, and fishing methods to factors\neval_data$angaus &lt;- as.factor(eval_data$angaus_obs)\neval_data$ds_dam &lt;- as.factor(eval_data$ds_dam)\neval_data$method &lt;- as.factor(eval_data$method)\n\n#fit final model to big dataset\n#class predictions\neval_classpred &lt;- final_fit |&gt; \n  predict(eval_data)\n\n#probability predictions\neval_probpred &lt;- final_fit |&gt; \n  predict(eval_data, type = 'prob')\n\neval_df &lt;- cbind(eval_classpred, eval_probpred, eval_data)\n\n#accuracy measure\naccuracy &lt;- accuracy(eval_df, truth = angaus, estimate = .pred_class)\n#roc_auc measure \n#roc &lt;- yardstick::roc_auc(eval_df, truth = angaus, estimate = .pred_0)\n\n# metrics &lt;- rbind(accuracy, roc)\n# tab_df(metrics, \n#        title = 'Table 7',\n#        digits = 4,\n#        footnote = 'Accuracy and Area Under the Receiver Operator Curve (ROC) of the model fit to evaluation data.',\n#        show.footnote = TRUE)\n\n\n\nHow does this model perform on the evaluation data?\nThe final model, fit to the evaluation data, has an accuracy of 0.82, and the ROC area under the curve is 0.85. For comparison, the model produced by Edith et al. had a ROC area under the curve of 0.858."
  },
  {
    "objectID": "posts/boosted_eels/index.html#references",
    "href": "posts/boosted_eels/index.html#references",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "References",
    "text": "References\n[1] Elith, J., Leathwick, J.R. and Hastie, T. (2008), A working guide to boosted regression trees. Journal of Animal Ecology, 77: 802-813. https://doi.org/10.1111/j.1365-2656.2008.01390.x"
  },
  {
    "objectID": "posts/boosted_eels/index.html#description-1",
    "href": "posts/boosted_eels/index.html#description-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Description:",
    "text": "Description:\nIn this post, I perform a case study example of species distribution modeling in a reproduction of the work done by Edith et al. 2008 [1]. For this case study, we model the short-finned eel (Anguilla australis) species using Boosted Regression Trees. This analysis is derived from an assignment for EDS232: Machine Learning in Environmental Science, as part of the curriculum for UCSB’s Master’s of Environmental Data Science program.\nBoosted regression trees, also known as gradient boosting machines, are machine learning techniques that combine concepts of regression trees (relating responses to predictors using recursive binary splits) and iterative boosting (an adaptive method for combining simple models to improve predictive performance). In this case study, decision trees are built sequentially using extreme gradient boosting to classify the presence or absence of short-finned eel in a given location with covariates including temperature, slope, rainy days, etc. The work provided by Edith et al. utilizes the {gbm} package in R, while this analysis follows a {tidymodels} approach in R."
  },
  {
    "objectID": "posts/boosted_eels/index.html#data-1",
    "href": "posts/boosted_eels/index.html#data-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Data",
    "text": "Data\nOur data for this analysis, “eel.model.data.csv” were retrived from the supplemental information of Edith et al. 2008. These data include the following variables:\n\n\n\nFigure 1: Table 1. from Elith et al. 2008 displaying the variables included in the analysis.\n\n\n#| include: false\nlibrary(readr)\neel_data_raw &lt;- read_csv(\"/Users/gabriellesmith/MEDS/EDS232/labs/eel.model.data.csv\") \n#| warning: false\n# load required libraries\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(glmnet)\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(sjPlot)\nlibrary(pROC)\nlibrary(RColorBrewer)\n\n\neel_data &lt;- eel_data_raw |&gt; \n  janitor::clean_names() \n\n# remove site number from modeling data\neel_model &lt;- eel_data[,-1]\n\n# convert presence of angaus, downstream obstructions, and fishing methods to factors\neel_model$angaus &lt;- as.factor(eel_model$angaus)\neel_model$ds_dam &lt;- as.factor(eel_model$ds_dam)\neel_model$method &lt;- as.factor(eel_model$method)\n\ntab_df(eel_data[1:5,],\n       title = \"Table. 1\")"
  },
  {
    "objectID": "posts/boosted_eels/index.html#split-and-resample-1",
    "href": "posts/boosted_eels/index.html#split-and-resample-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Split and Resample",
    "text": "Split and Resample\nWe split the above data into a training and test set, stratifying by the outcome score (angaus) to maintain class balance, improve generalization, and ensure the reliability of evaluation in modeling performances. We then use a 10-fold cross validation to resample the training set, also stratified by outcome score.\n# set a seed for reproducibility\nset.seed(123)\n\n#stratified sampling with the {rsample} package\neel_split &lt;- initial_split(data = eel_model, prop = 0.7, strata = angaus)\n\neel_train &lt;- training(eel_split)\neel_test &lt;- testing(eel_split)\n\n# 10-fold cross validation, stratified by our outcome variable, angaus \ncv_folds &lt;- eel_train |&gt; \n  vfold_cv(v=10, strata = angaus)"
  },
  {
    "objectID": "posts/boosted_eels/index.html#preprocess-1",
    "href": "posts/boosted_eels/index.html#preprocess-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Preprocess",
    "text": "Preprocess\nNext, we create a recipe to prepape the data for the XGBoost model. For this analysis, we are interested in predicting the binary outcome variable angaus, which indicates presence or absence of the eel species Anguilla australis.\n# create a recipe \nboost_rec &lt;- recipe(angaus ~., data = eel_train) |&gt; \n  step_normalize(all_numeric()) |&gt; \n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |&gt; \n  prep()\n\n# bake to check recipe\nbaked_train &lt;- bake(boost_rec, eel_train) \nbaked_test &lt;- bake(boost_rec, eel_test)"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tuning-xgboost-1",
    "href": "posts/boosted_eels/index.html#tuning-xgboost-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tuning XGBoost",
    "text": "Tuning XGBoost\n\nTune Learning Rate\nTo begin, we perform tuning on just the learn_rate parameter.\nWe create a model specification using {xbgoost} for the estimation, specifying only the learn_rate parameter for tuning.\n#create a model for specification\nlearn_spec &lt;- boost_tree(learn_rate = tune()) |&gt; \n  set_engine('xgboost') |&gt; \n  set_mode('classification') \nNext, we build a grid to tune our model by using a range of learning rate parameter values.\n#set a grid to tune hyperparameter values\nlearn_grid &lt;- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))\nThen, we define a new workflow and tune the model using the learning rate grid.\n#define a new workflow \nlearn_wf &lt;- workflow() |&gt; \n  add_model(learn_spec) |&gt; \n  add_recipe(boost_rec)\n\ndoParallel::registerDoParallel()\nset.seed(123)\n\n#tune the model\nlearn_tune &lt;- learn_wf |&gt; \n  tune_grid(cv_folds, grid=learn_grid) \n\n#show the performance of the best models \nshow_best(learn_tune, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 2',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various learning rate parameter values.',\n         show.footnote=TRUE)\n\n#save the best model parameters to be used in future tuning\nbest_learnrate &lt;- as.numeric(show_best(learn_tune, metric = 'roc_auc')[1,1])"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tune-tree-parameters-1",
    "href": "posts/boosted_eels/index.html#tune-tree-parameters-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tune Tree Parameters",
    "text": "Tune Tree Parameters\nFollowing the tuning of the learning rate parameter, we create a new specification with a set optimized learning rate from our previous optimization. Now, we shift our focus on tuning the tree parameters.\n#create a new specificatin with set learning rate \ntree_spec &lt;- boost_tree(learn_rate = best_learnrate,\n                         min_n = tune(),\n                         tree_depth = tune(),\n                         loss_reduction = tune(),\n                         trees = 3000) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost')\nAgain, we create a tuning grid, this time utilizing grid_max_entropy() to get a representative sampling of the parameter space.\n#specify parameters for the tuning grid \ntree_params &lt;- dials::parameters(min_n(),\n                           tree_depth(),\n                           loss_reduction())\n\n#set the tuning grid \ntree_grid &lt;- grid_max_entropy(tree_params, size = 20)\n\n#define a new workflow \ntree_wf &lt;- workflow() |&gt; \n  add_model(tree_spec) |&gt; \n  add_recipe(boost_rec)\n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n#tune the model\ntree_tuned &lt;- tree_wf |&gt; \n  tune_grid(cv_folds, grid = tree_grid)\n\n#show the performance of the best models \nshow_best(tree_tuned, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 3',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various tree parameter values.',\n         show.footnote = TRUE)\n\n#save the best model parameters to be used for future tuning\nbest_minn &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,1])\n\nbest_treedepth &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,2])\n\nbest_lossreduction &lt;- as.numeric(show_best(tree_tuned, metric = 'roc_auc')[1,3])"
  },
  {
    "objectID": "posts/boosted_eels/index.html#tune-stochastic-parameters-1",
    "href": "posts/boosted_eels/index.html#tune-stochastic-parameters-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Tune Stochastic Parameters",
    "text": "Tune Stochastic Parameters\nWe create one final specification, setting the learn rate and tree parameters to their optimal values defined in previous tuning iterations. Our final tuning is of the stochastic parameters.\n#create a new specificatin with set learning rate and tree parameters\nstoch_tune &lt;- boost_tree(learn_rate = best_learnrate,\n                         min_n = best_minn,\n                         tree_depth = best_treedepth,\n                         loss_reduction = best_lossreduction,\n                         trees = 3000,\n                         mtry = tune(), \n                         sample_size = tune()) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost')\nWe set up a tuning grid, again utilizing grid_max_entropy().\n#set parameters for the tuning grid \nstoch_params &lt;- parameters(finalize(mtry(), eel_train),\n                          sample_size = sample_prop())\n\n#set the tuning grid \nstoch_grid &lt;- grid_max_entropy(stoch_params, size = 20)\n\n#define a new workflow \nstoch_wf &lt;- workflow() |&gt; \n  add_model(stoch_tune) |&gt; \n  add_recipe(boost_rec) \n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n#tune the model \nstoch_tuned &lt;- stoch_wf |&gt; \n  tune_grid(cv_folds, grid = stoch_grid)\n\n#show the performance of the best models \nshow_best(stoch_tuned, metric = 'roc_auc') |&gt; \n  tab_df(title = 'Table 4',\n         digits = 4,\n         footnote = 'Top performing models and their associated estimates for various stochiastic parameter values.',\n         show.footnote = TRUE)\n\n#save the best model parameters to be used for model finalization\nbest_mtry &lt;- as.numeric(show_best(stoch_tuned, metric = 'roc_auc')[1,1])\nbest_samplesize &lt;- as.numeric(show_best(stoch_tuned, metric = 'roc_auc')[1,2])\nNow that we have tuned all of our relevant hyperparameters, we assemble a final workflow and do a final fit.\n#create a final specification with all set optimized parameters \nfinal_model &lt;-  boost_tree(learn_rate = best_learnrate,\n                         min_n = best_minn,\n                         tree_depth = best_treedepth,\n                         loss_reduction = best_lossreduction,\n                         trees = 3000,\n                         mtry = best_mtry, \n                         sample_size = best_samplesize) |&gt; \n  set_mode('classification') |&gt; \n  set_engine('xgboost') \n\n#define a final workflow \nfinal_wf &lt;- workflow() |&gt; \n  add_model(final_model) |&gt; \n  add_recipe(boost_rec) \n\n#fit training data on final wf\nfinal_fit &lt;- final_wf |&gt; \n  fit(eel_train)\n\nfinal_eel_fit &lt;- last_fit(final_model, angaus~., eel_split)\n\nfinal_pred &lt;- as.data.frame(final_eel_fit$.predictions)\n\ntab_df(head(final_pred),\n       title = 'Table 5',\n       digits = 4,\n       footnote = 'Predictions of Angaus presence on test data.',\n       show.footnote = TRUE)\n#bind predictions and original data \neel_test_bind &lt;- cbind(eel_test, final_eel_fit$.predictions)\n\n#remove duplicate column\neel_test_bind &lt;- eel_test_bind[,-1]\n\n#compute a confusion matrix\nconfusion_matrix &lt;- eel_test_bind |&gt; \n  yardstick::conf_mat(truth = angaus, estimate = .pred_class)\n\nautoplot(confusion_matrix, type = \"heatmap\") +\n  scale_fill_gradient(low = \"#C7E9FB\", high = \"#084594\") +\n  theme(axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\")) +\n  labs(title = \"Figure 2: Confusion matrix of predictions on test data.\")\n# store accuracy metrics \nfinal_metrics &lt;- final_eel_fit$.metrics\n\ntab_df(final_metrics,\n       title = 'Table 6',\n       digits = 4,\n       footnote = 'Accuracy and Area Under the Receiver Operator Curve (ROC) of the final fit.',\n       show.footnote = TRUE)\nThe final model has an accuracy of 0.80. The ROC area under the curve is 0.82."
  },
  {
    "objectID": "posts/boosted_eels/index.html#fit-model-evaluation-data-and-compare-performance-1",
    "href": "posts/boosted_eels/index.html#fit-model-evaluation-data-and-compare-performance-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "Fit model evaluation data and compare performance",
    "text": "Fit model evaluation data and compare performance\n#read in evaluation data \neval_data &lt;- read_csv('eel.eval.data.csv', show_col_types = FALSE) |&gt; \n  janitor::clean_names() \n\n# convert presence of angaus, downstream obstructions, and fishing methods to factors\neval_data$angaus &lt;- as.factor(eval_data$angaus_obs)\neval_data$ds_dam &lt;- as.factor(eval_data$ds_dam)\neval_data$method &lt;- as.factor(eval_data$method)\n\n#fit final model to big dataset\n#class predictions\neval_classpred &lt;- final_fit |&gt; \n  predict(eval_data)\n\n#probability predictions\neval_probpred &lt;- final_fit |&gt; \n  predict(eval_data, type = 'prob')\n\neval_df &lt;- cbind(eval_classpred, eval_probpred, eval_data)\n\n#accuracy measure\naccuracy &lt;- accuracy(eval_df, truth = angaus, estimate = .pred_class)\n#roc_auc measure \n#roc &lt;- yardstick::roc_auc(eval_df, truth = angaus, estimate = .pred_0)\n\n# metrics &lt;- rbind(accuracy, roc)\n# tab_df(metrics, \n#        title = 'Table 7',\n#        digits = 4,\n#        footnote = 'Accuracy and Area Under the Receiver Operator Curve (ROC) of the model fit to evaluation data.',\n#        show.footnote = TRUE)\n\nHow does this model perform on the evaluation data?\nThe final model, fit to the evaluation data, has an accuracy of 0.82, and the ROC area under the curve is 0.85. For comparison, the model produced by Edith et al. had a ROC area under the curve of 0.858."
  },
  {
    "objectID": "posts/boosted_eels/index.html#references-1",
    "href": "posts/boosted_eels/index.html#references-1",
    "title": "Eel Species Distribution Modeling Using Boosted Trees",
    "section": "References",
    "text": "References\n[1] Elith, J., Leathwick, J.R. and Hastie, T. (2008), A working guide to boosted regression trees. Journal of Animal Ecology, 77: 802-813. https://doi.org/10.1111/j.1365-2656.2008.01390.x"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "workshops.html#welcome",
    "href": "workshops.html#welcome",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "workshops.html#education",
    "href": "workshops.html#education",
    "title": "Gabrielle Smith",
    "section": "Education",
    "text": "Education\n\nGraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (June 2023)\nMaster of Environmental Data Science\n\n\nUndergraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (March 2022)\nBachelor of Science in Statistics and Data Science"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Gabrielle Smith",
    "section": "Education",
    "text": "Education\n\nGraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (June 2023)\nMaster of Environmental Data Science\n\n\nUndergraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (March 2022)\nBachelor of Science in Statistics and Data Science"
  },
  {
    "objectID": "index.html#welcome-1",
    "href": "index.html#welcome-1",
    "title": "Gabrielle Smith",
    "section": "Welcome!",
    "text": "Welcome!\nI’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "index.html#education-1",
    "href": "index.html#education-1",
    "title": "Gabrielle Smith",
    "section": "Education",
    "text": "Education\n\nGraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (June 2023)\nMaster of Environmental Data Science\n\n\nUndergraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (March 2022)\nBachelor of Science in Statistics and Data Science"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I grew up in San Diego, California. I moved to Santa Barbara in 2018 to pursue a Bachelor’s of Science in Statistics and Data Science. During that time, I experimented, a lot, with different educational enthusiasms.\nThroughout my life, I have always had a passion for people and the world around us. This passion turned into a career aspiration after a transformative volunteer trip to Thailand with GIVE Volunteers in 2019.\nDuring my two week experience abroad, I had the opportunity to establish a functional permaculture agricultural system in a remote village in Mueang Kong. For context, permaculture is a holistic design philosophy that promotes sustainable and regenerative farming practices. It strives to maximize productivity while minimizing negative environmental impacts by emulating natural patterns and processes. To learn more about permaculture in agriculture, you can find additional information here.\nI was fascinated by this pursuit of harmony between people and the natural world, and it has since become the driving force behind both my personal and professional goals. Inspired by this experience, I decided to pursue a Master’s degree in Environmental Data Science at the University of California, Santa Barbara. This choice allowed me to merge my educational background with my aspiration to contribute to systems that promote the well-being of both people and the planet.\nSince then, I have honed a diverse skill set in data science, equipping me with the tools to employ data-driven decision making in addressing environmental challenges in a sustainable and equitable way. My aim is to apply these skills in future career endeavors, working towards a better world that cares for the health of all living beings."
  },
  {
    "objectID": "about.html#welcome",
    "href": "about.html#welcome",
    "title": "Gabrielle Smith",
    "section": "Welcome!",
    "text": "Welcome!\nI’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Gabrielle Smith",
    "section": "Education",
    "text": "Education\n\nGraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (June 2023)\nMaster of Environmental Data Science\n\n\nUndergraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (March 2022)\nBachelor of Science in Statistics and Data Science"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "posts.html#welcome",
    "href": "posts.html#welcome",
    "title": "Gabrielle Smith",
    "section": "",
    "text": "I’m Gabrielle, and I am a recent graduate of the Bren School of Environmental Science & Management at the University of California, Santa Barbara with a Master’s in Environmental Data Science. I also earned a Statistics and Data Science B.S. from the University of California, Santa Barbara in 2022.\nI’m passionate about leveraging remote sensing techniques to address our environmental challenges and climate issues. If you’re curious about some of the projects I’ve worked on, you came to the right place!"
  },
  {
    "objectID": "posts.html#education",
    "href": "posts.html#education",
    "title": "Gabrielle Smith",
    "section": "Education",
    "text": "Education\n\nGraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (June 2023)\nMaster of Environmental Data Science\n\n\nUndergraduate\nUniversity of California, Santa Barbara | Santa Barbara, CA (March 2022)\nBachelor of Science in Statistics and Data Science"
  }
]